# 大模型相关问题

## 幻觉
幻觉指的是一本正经的胡说八道：看似流畅自然的表述，实则不符合事实或者是错误的。

分类：
- 内在幻觉：生成的内容与源内容相矛盾；
- 外部幻觉：生成的内容不能从源内容中得到验证，既不受源内容支持也不受其反驳；

产生幻觉的原因：
1. 数据源缺陷：
   1) 知识错误: 预训练注入错误的知识；
   2) 重复偏差：数据大量重复，导致模型产生偏好；
   3) 社会偏见：训练数据自带社会偏见，如：人种歧视；
   4) 长尾分布：长尾知识学习不充分；
2. prompt指令复杂；
3. 训练阶阶段缺陷：
   1) 位置编码: 远程衰减属性；
   2) 置信度对齐：RLHF的偏好对齐可能会改变模型本身对答案的置信度；
4. 推理阶段缺陷：
   1) 解码过程中的随机性：如temperature、tok-k、top-p等；
   2) 解码过程的错误累计：如果前面内容存在错误，后面误差越来越大。

解决方法：
1. 提高数据质量（包括预训练数据和sft数据），进行数据清洗；
2. prompt工程：采用更合理的prompt（如：cot），或agent（如：ReAct）或要求大模型不确定的不回答
3. 采用更长更好的位置编码；
4. RAG借助外部知识，严格按照给定知识回答；
5. 集成学习：将多个模型的预测结果进行集成，以提高预测的准确性和鲁棒性